# streamlit_app.py
# -*- coding: utf-8 -*-
import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn import datasets
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# UMAP ä¸æ˜¯ sklearn å…§å»ºï¼Œrequirements å·²åŒ…å« umap-learn
try:
    import umap
    HAS_UMAP = True
except Exception:
    HAS_UMAP = False

st.set_page_config(page_title="Iris åˆ†é¡å¯è¦–åŒ– Appï¼ˆMatplotlib ç‰ˆï¼‰", layout="wide")

# -----------------------------
# è¼‰å…¥è³‡æ–™
# -----------------------------
@st.cache_data
def load_iris():
    iris = datasets.load_iris()
    X = pd.DataFrame(iris.data, columns=iris.feature_names)
    y = pd.Series(iris.target, name="target")
    target_names = iris.target_names
    return X, y, target_names

X, y, target_names = load_iris()

# Feature åˆ¥åï¼ˆä¸­æ–‡ï¼‰
feature_alias = {
    "sepal length (cm)": "èŠ±è¼é•·",
    "sepal width (cm)": "èŠ±è¼å¯¬",
    "petal length (cm)": "èŠ±ç“£é•·",
    "petal width (cm)": "èŠ±ç“£å¯¬",
}

# -----------------------------
# å´é‚Šæ¬„ï¼šæ¨¡å‹èˆ‡é™ç¶­æ–¹å¼
# -----------------------------
st.sidebar.title("è¨­å®š")
model_name = st.sidebar.selectbox(
    "é¸æ“‡åˆ†é¡æ¨¡å‹",
    ["Logistic Regression", "SVM (RBF)", "Random Forest"],
    index=0,  # æ˜ç¢ºæŒ‡å®š indexï¼Œé¿å…ç‹€æ…‹é‚„åŸç”¢ç”Ÿè¶Šç•Œ
    key="model_name_v1"
)

# åŸºæœ¬åƒæ•¸
if model_name == "Logistic Regression":
    C = st.sidebar.slider("Cï¼ˆæ­£å‰‡åŒ–å¼·åº¦å€’æ•¸ï¼‰", 0.01, 10.0, 1.0, 0.01, key="lr_C")
elif model_name == "SVM (RBF)":
    C = st.sidebar.slider("Cï¼ˆæ‡²ç½°ä¿‚æ•¸ï¼‰", 0.1, 10.0, 1.0, 0.1, key="svm_C")
    gamma = st.sidebar.select_slider("gamma", options=["scale", "auto"], value="scale", key="svm_gamma")
elif model_name == "Random Forest":
    n_estimators = st.sidebar.slider("æ¨¹çš„æ•¸é‡ n_estimators", 50, 400, 200, 10, key="rf_n")
    max_depth = st.sidebar.slider("æœ€å¤§æ·±åº¦ max_depth (0 ç‚º None)", 0, 20, 0, 1, key="rf_depth")

dr_options = ["PCA", "t-SNE"]
if HAS_UMAP:
    dr_options.append("UMAP")

# æ˜ç¢ºæŒ‡å®šå®‰å…¨é è¨­ indexï¼Œä¸¦ä½¿ç”¨ä¾ HAS_UMAP è®Šå‹•çš„ key ä»¥é¿å…èˆŠçš„ index è¢«æ²¿ç”¨
default_dr = "PCA" if "PCA" in dr_options else dr_options[0]
dr_method = st.sidebar.selectbox(
    "é™ç¶­æ–¹æ³•ï¼ˆ2Dï¼‰",
    dr_options,
    index=dr_options.index(default_dr),
    key=f"dr_method_{int(HAS_UMAP)}",
)

random_state = st.sidebar.number_input("random_stateï¼ˆç©©å®šé‡ç¾ï¼‰", min_value=0, value=42, step=1, key="rand_state")

# -----------------------------
# å»ºç«‹æ¨¡å‹
# -----------------------------
@st.cache_resource(show_spinner=False)
def build_model(model_name, params, random_state):
    if model_name == "Logistic Regression":
        model = Pipeline([
            ("scaler", StandardScaler()),
            ("clf", LogisticRegression(C=params["C"], max_iter=1000, multi_class="auto"))
        ])
    elif model_name == "SVM (RBF)":
        model = Pipeline([
            ("scaler", StandardScaler()),
            ("clf", SVC(C=params["C"], gamma=params["gamma"], probability=True, random_state=random_state))
        ])
    else:  # Random Forest
        md = params["max_depth"] if params["max_depth"] > 0 else None
        model = RandomForestClassifier(n_estimators=params["n_estimators"], max_depth=md, random_state=random_state)
    return model

params = {}
if model_name == "Logistic Regression":
    params["C"] = C
elif model_name == "SVM (RBF)":
    params["C"] = C
    params["gamma"] = gamma
else:
    params["n_estimators"] = n_estimators
    params["max_depth"] = max_depth

model = build_model(model_name, params, random_state)

# äº¤å‰é©—è­‰ï¼ˆé¡¯ç¤ºæ¦‚ç•¥è¡¨ç¾ï¼‰
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)
scores = cross_val_score(model, X, y, cv=cv, scoring="accuracy")
st.sidebar.markdown(f"**CV (5-fold) æº–ç¢ºç‡**ï¼š{scores.mean():.3f} Â± {scores.std():.3f}")

# -----------------------------
# ä½¿ç”¨è€…è¼¸å…¥ï¼ˆå››å€‹ç‰¹å¾µï¼‰
# -----------------------------
def number_slider(label, series, step=0.1, key=None):
    return st.slider(
        label,
        float(series.min()),
        float(series.max()),
        float(series.mean()),
        step=step,
        key=key,
    )

st.sidebar.markdown("---")
st.sidebar.subheader("è¼¸å…¥è¦é æ¸¬çš„æ¨£æœ¬")
sl = number_slider(f"{feature_alias['sepal length (cm)']}ï¼ˆcmï¼‰", X["sepal length (cm)"], key="sl")
sw = number_slider(f"{feature_alias['sepal width (cm)']}ï¼ˆcmï¼‰", X["sepal width (cm)"], key="sw")
pl = number_slider(f"{feature_alias['petal length (cm)']}ï¼ˆcmï¼‰", X["petal length (cm)"], key="pl")
pw = number_slider(f"{feature_alias['petal width (cm)']}ï¼ˆcmï¼‰", X["petal width (cm)"], key="pw")

user_X = np.array([[sl, sw, pl, pw]])

# -----------------------------
# è¨“ç·´æ¨¡å‹ä¸¦é æ¸¬
# -----------------------------
model.fit(X, y)
pred_class_idx = model.predict(user_X)[0]
try:
    proba = model.predict_proba(user_X)[0]
except Exception:
    proba = np.array([np.nan] * len(target_names))

pred_class = target_names[pred_class_idx]

# -----------------------------
# é™ç¶­ä¸¦æº–å‚™ 2D è³‡æ–™
# -----------------------------
@st.cache_data(show_spinner=False)
def reduce_dim_and_project(X_df, method, user_X, random_state=42):
    subtitle = ""
    if method == "PCA":
        reducer = PCA(n_components=2, random_state=random_state)
        components = reducer.fit_transform(X_df)
        explained = reducer.explained_variance_ratio_
        subtitle = f"PCAï¼ˆè§£é‡‹è®Šç•° {explained[0]:.2%} + {explained[1]:.2%}ï¼‰"
        proj_user = reducer.transform(user_X)[0]
    elif method == "t-SNE":
        reducer = TSNE(n_components=2, random_state=random_state, init="pca", learning_rate="auto")
        components = reducer.fit_transform(X_df)
        subtitle = "t-SNE"
        # ç”¨æœ€è¿‘é„°çš„ 2D ä½ç½®è¿‘ä¼¼
        dists = np.linalg.norm(X_df.values - user_X, axis=1)
        proj_user = components[np.argmin(dists)]
    elif method == "UMAP" and HAS_UMAP:
        reducer = umap.UMAP(n_components=2, random_state=random_state)
        components = reducer.fit_transform(X_df)
        subtitle = "UMAP"
        dists = np.linalg.norm(X_df.values - user_X, axis=1)
        proj_user = components[np.argmin(dists)]
    else:
        reducer = PCA(n_components=2, random_state=random_state)
        components = reducer.fit_transform(X_df)
        explained = reducer.explained_variance_ratio_
        subtitle = f"PCAï¼ˆè§£é‡‹è®Šç•° {explained[0]:.2%} + {explained[1]:.2%}ï¼‰"
        proj_user = reducer.transform(user_X)[0]

    df2d = pd.DataFrame(components, columns=["dim1", "dim2"])
    return df2d, subtitle, proj_user

df2d, subtitle, user_point = reduce_dim_and_project(X, dr_method, user_X, random_state=random_state)
df2d["target"] = y.map(lambda i: target_names[i])

# -----------------------------
# Matplotlib ç¹ªåœ–ï¼ˆä¸æŒ‡å®šè‰²å½©èˆ‡æ¨£å¼ï¼‰
# -----------------------------
col1, col2 = st.columns([2, 1])

with col1:
    fig, ax = plt.subplots()
    # é€é¡åˆ¥ç•«æ•£é»ï¼ˆé¡è‰²ç”± Matplotlib é è¨­å¾ªç’°ï¼‰
    for cls in target_names:
        data = df2d[df2d["target"] == cls]
        ax.scatter(data["dim1"], data["dim2"], label=cls)
    # ä½¿ç”¨è€…é»ï¼ˆä»¥ 'x' æ¨™è¨˜ï¼‰
    ax.scatter([user_point[0]], [user_point[1]], marker="x", s=100, label="Your sample")
    ax.set_title(f"Iris 2D è¦–è¦ºåŒ–ï¼ˆ{subtitle}ï¼‰")
    ax.set_xlabel("dim1")
    ax.set_ylabel("dim2")
    ax.legend()
    st.pyplot(fig)

with col2:
    st.subheader("é æ¸¬çµæœ")
    st.markdown(f"**æ¨¡å‹**ï¼š{model_name}")
    st.markdown(f"**é æ¸¬å“ç¨®**ï¼š:blue[{pred_class}]")
    if not np.isnan(proba).any():
        proba_df = pd.DataFrame({"class": target_names, "probability": proba}).sort_values("probability", ascending=False)
        st.dataframe(proba_df, use_container_width=True)
    else:
        st.info("æ­¤æ¨¡å‹ç›®å‰ç„¡æ©Ÿç‡è¼¸å‡ºï¼ˆpredict_probaï¼‰ï¼Œåƒ…é¡¯ç¤ºé¡åˆ¥é æ¸¬ã€‚")
    st.markdown("---")
    st.caption("ğŸ’¡ å·¦å´å¯èª¿æ•´é™ç¶­æ–¹æ³•èˆ‡æ¨¡å‹åƒæ•¸ï¼Œä¸¦æ‹–å‹•æ»‘æ¡¿è¼¸å…¥ç‰¹å¾µå€¼ã€‚")

st.markdown("---")
with st.expander("é¡¯ç¤ºè³‡æ–™é è¦½èˆ‡æè¿°çµ±è¨ˆ"):
    st.dataframe(pd.concat([X, y.rename('target_idx')], axis=1).head())
    st.write("æè¿°çµ±è¨ˆï¼š")
    st.write(X.describe())

st.caption("Built with Streamlit Â· scikit-learn Â· Matplotlib")
